#!/usr/bin/env python3
"""
üöÄ BATCH OPTIMIZATION QR - Sistema de Optimizaci√≥n de Preguntas-Respuestas
===========================================================================
Sistema para procesar datasets usando adaptive_processor e identificar conversaciones 
con √≠ndice de calidad < 0.6 para generar patrones optimizados.

FUNCIONALIDAD:
- Procesa datasets usando adaptive_processor con 5 fundamentales + 3 espec√≠ficas
- Identifica conversaciones con quality_score < 0.6
- Genera reportes por batch despu√©s de procesar cada archivo
- Crea patrones optimizados para mejorar la calidad del dataset

CONFIGURACI√ìN OPTIMIZADA:
- Dataset fuente: data_test_ultra_hybrid (1 archivo de prueba)
- Fundamentales: 5 (umbral: 0.9)
- Espec√≠ficas: 3 (umbral: 0.7)
- Logs reducidos y reportes por batch
"""

import json
import os
import sys
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional
import shutil
from collections import defaultdict

# Importar m√≥dulos locales
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

try:
    from content_manager import ContentManager
    print("‚úÖ ContentManager importado")
except ImportError as e:
    print(f"‚ö†Ô∏è Warning importando ContentManager: {e}")
    class ContentManager:
        def __init__(self, **kwargs):
            pass

try:
    from category_system import CategorySystem
    print("‚úÖ CategorySystem importado")
except ImportError as e:
    print(f"‚ö†Ô∏è Warning importando CategorySystem: {e}")
    class CategorySystem:
        def get_category_config(self, category):
            return {'keywords': [category]}

try:
    # Intentar importar formation system
    import importlib.util
    formation_spec = importlib.util.spec_from_file_location("formation_system", current_dir / "formation_system.py")
    if formation_spec and formation_spec.loader:
        formation_module = importlib.util.module_from_spec(formation_spec)
        formation_spec.loader.exec_module(formation_module)
        FormationFundamentalSystem = formation_module.FormationFundamentalSystem
        print("‚úÖ FormationFundamentalSystem importado")
    else:
        raise ImportError("No se pudo cargar formation_system")
        
except ImportError as e:
    print(f"‚ö†Ô∏è Warning: {e}")
    # Fallback b√°sico
    class FormationFundamentalSystem:
        def __init__(self, output_dir):
            self.output_dir = output_dir
            
        def validate_conversation(self, conversation):
            return {
                'is_valid': True,
                'quality_score': conversation.get('quality_score', 0.8),
                'issues': []
            }
    category_spec.loader.exec_module(category_module)
    
    # Crear clase CategorySystem desde el m√≥dulo
    class CategorySystem:
        def __init__(self):
            self.categories = category_module.MAIN_CATEGORIES
        
        def get_category_config(self, category: str) -> dict:
            return self.categories.get(category, {})
        
        def get_all_categories(self) -> dict:
            return self.categories
            
except ImportError as e:
    print(f"Warning: {e}")
    # Fallback b√°sico
    class CategorySystem:
        def __init__(self):
            self.categories = {}
        def get_category_config(self, category: str) -> dict:
            return {}
        def get_all_categories(self) -> dict:
            return {}


class BatchOptimizationQR:
    """Sistema principal para optimizaci√≥n de preguntas-respuestas de baja calidad"""
    
    def __init__(self, 
                 source_dir: str = "data_conversations_complete",
                 output_dir: str = "fundamentals_training",
                 quality_threshold: float = 0.6,
                 fundamental_questions: int = 5,
                 specific_questions: int = 3):
        
        self.source_dir = Path(source_dir)
        self.output_dir = Path(output_dir)
        self.quality_threshold = quality_threshold
        self.fundamental_questions = fundamental_questions
        self.specific_questions = specific_questions
        self.low_quality_dir = self.output_dir / "low_quality_patterns"
        
        # Crear directorios de salida
        self.output_dir.mkdir(exist_ok=True)
        self.low_quality_dir.mkdir(exist_ok=True)
        
        # Inicializar sistemas con nuevos par√°metros
        self.category_system = CategorySystem()
        self.content_manager = ContentManager(
            questions_per_article=fundamental_questions + specific_questions,
            fundamental_questions=fundamental_questions,
            specific_questions=specific_questions
        )
        self.formation_system = FormationFundamentalSystem(str(self.output_dir))
        
        # Inicializar generador inteligente de preguntas
        from formation_fundamental.intelligent_question_generator import IntelligentQuestionGenerator
        self.intelligent_generator = IntelligentQuestionGenerator(
            questions_per_category=fundamental_questions + specific_questions,
            base_questions=fundamental_questions,
            specific_questions=specific_questions
        )
        
        # Estad√≠sticas de procesamiento mejoradas
        self.stats = {
            'total_conversations': 0,
            'low_quality_conversations': 0,
            'fundamental_patterns_identified': 0,
            'specific_patterns_identified': 0,
            'improved_fundamental_questions': 0,
            'improved_specific_questions': 0,
            'categories_processed': 0,
            'processing_time': 0,
            'quality_improvements': {
                'fundamental_avg_before': 0.0,
                'fundamental_avg_after': 0.0,
                'specific_avg_before': 0.0,
                'specific_avg_after': 0.0
            }
        }
        
        print(f"üöÄ BATCH OPTIMIZATION QR INICIALIZADO (Enhanced)")
        print(f"üìÅ Fuente: {self.source_dir}")
        print(f"üìÅ Salida: {self.output_dir}")
        print(f"üéØ Umbral de calidad: {self.quality_threshold}")
        print(f"üìã Preguntas fundamentales: {self.fundamental_questions} (umbral: 0.9)")
        print(f"üéØ Preguntas espec√≠ficas: {self.specific_questions} (umbral: 0.7)")
    
    def run_optimization_pipeline(self) -> Dict[str, Any]:
        """Ejecuta el pipeline completo de optimizaci√≥n"""
        start_time = datetime.now()
        
        print("\nüîÑ INICIANDO PIPELINE DE OPTIMIZACI√ìN QR")
        print("=" * 60)
        
        try:
            # FASE 1: Identificar conversaciones de baja calidad
            print("üìã FASE 1: Identificaci√≥n de conversaciones de baja calidad")
            low_quality_data = self._identify_low_quality_conversations()
            
            # FASE 2: Analizar patrones problem√°ticos
            print("\nüîç FASE 2: An√°lisis de patrones problem√°ticos")
            problematic_patterns = self._analyze_problematic_patterns(low_quality_data)
            
            # FASE 3: Generar patrones optimizados
            print("\n‚öôÔ∏è FASE 3: Generaci√≥n de patrones optimizados")
            optimized_patterns = self._generate_optimized_patterns(problematic_patterns)
            
            # FASE 4: Crear preguntas mejoradas
            print("\nüìù FASE 4: Creaci√≥n de preguntas mejoradas")
            improved_questions = self._generate_improved_questions(optimized_patterns)
            
            # FASE 5: Validar mejoras
            print("\nüß™ FASE 5: Validaci√≥n de mejoras")
            validation_results = self._validate_improvements(improved_questions)
            
            # FASE 6: Generar archivos fundamentals_training
            print("\nüíæ FASE 6: Generaci√≥n de archivos fundamentals_training")
            self._generate_fundamentals_training(optimized_patterns, improved_questions)
            
            # FASE 7: Crear reportes
            print("\nüìä FASE 7: Generaci√≥n de reportes")
            self._generate_reports(low_quality_data, optimized_patterns, validation_results)
            
            end_time = datetime.now()
            self.stats['processing_time'] = (end_time - start_time).total_seconds()
            
            print(f"\n‚úÖ PIPELINE COMPLETADO EN {self.stats['processing_time']:.2f} segundos")
            return self.stats
            
        except Exception as e:
            print(f"‚ùå Error en pipeline: {e}")
            raise
    
    def _identify_low_quality_conversations(self) -> Dict[str, List[Dict]]:
        """Identifica conversaciones con quality_score < threshold usando adaptive_processor"""
        print(f"   üîç Procesando {self.source_dir} con adaptive_processor")
        
        low_quality_data = defaultdict(list)
        
        if not self.source_dir.exists():
            print(f"   ‚ö†Ô∏è Directorio fuente no existe: {self.source_dir}")
            return dict(low_quality_data)
        
        # Usar adaptive_processor para procesar el dataset
        print(f"   üöÄ Ejecutando adaptive_processor en {self.source_dir}")
        
        # Crear directorio temporal para resultados
        temp_output = self.output_dir / "temp_processed"
        temp_output.mkdir(exist_ok=True, parents=True)
        
        try:
            # Ejecutar adaptive_processor
            from adaptive_processor import AdaptiveProcessor
            
            processor = AdaptiveProcessor(
                input_dir=str(self.source_dir),
                output_dir=str(temp_output),
                questions_per_article=self.fundamental_questions + self.specific_questions,
                fundamental_questions=self.fundamental_questions,
                specific_questions=self.specific_questions
            )
            
            print(f"   ‚öôÔ∏è Configuraci√≥n: {self.fundamental_questions} fundamentales + {self.specific_questions} espec√≠ficas")
            print(f"   üìä Umbrales: fundamentales ‚â• 0.9, espec√≠ficas ‚â• 0.7")
            
            # Procesar datasets con reportes por batch
            results = processor.process_datasets()
            
            print(f"   ‚úÖ Procesamiento completado")
            print(f"   üìä Estad√≠sticas del procesamiento:")
            if results:
                for key, value in results.items():
                    if isinstance(value, (int, float)):
                        print(f"     ‚Ä¢ {key}: {value:,}")
            
            # Ahora buscar conversaciones low_quality en los resultados
            print(f"   üîç Analizando conversaciones low_quality generadas")
            
            # Buscar archivos low_quality
            low_quality_dir = temp_output / "data_conversations_low_quality"
            if low_quality_dir.exists():
                for jsonl_file in low_quality_dir.glob("*.jsonl"):
                    category = jsonl_file.stem.replace("low_quality_", "")
                    print(f"     üìÇ Procesando low_quality: {category}")
                    
                    with open(jsonl_file, 'r', encoding='utf-8') as f:
                        for line_num, line in enumerate(f, 1):
                            line = line.strip()
                            if line:
                                try:
                                    conversation = json.loads(line)
                                    quality_score = conversation.get('quality_score', 0.0)
                                    
                                    self.stats['total_conversations'] += 1
                                    
                                    if quality_score < self.quality_threshold:
                                        conversation['source_file'] = str(jsonl_file)
                                        conversation['line_number'] = line_num
                                        conversation['category'] = category
                                        low_quality_data[category].append(conversation)
                                        self.stats['low_quality_conversations'] += 1
                                        
                                except json.JSONDecodeError:
                                    continue
            
            # Tambi√©n buscar en archivos principales de conversaciones
            conv_dirs = [temp_output / "data_conversations_complete"]
            for conv_dir in conv_dirs:
                if conv_dir.exists():
                    for category_dir in conv_dir.iterdir():
                        if category_dir.is_dir():
                            category_name = category_dir.name
                            conversation_files = list(category_dir.glob("*.jsonl"))
                            
                            if conversation_files:
                                print(f"     üìÇ Analizando categor√≠a: {category_name} ({len(conversation_files)} archivos)")
                            
                            for file_path in conversation_files:
                                try:
                                    with open(file_path, 'r', encoding='utf-8') as f:
                                        for line_num, line in enumerate(f, 1):
                                            line = line.strip()
                                            if line:
                                                try:
                                                    conversation = json.loads(line)
                                                    quality_score = conversation.get('quality_score', 1.0)
                                                    
                                                    self.stats['total_conversations'] += 1
                                                    
                                                    if quality_score < self.quality_threshold:
                                                        conversation['source_file'] = str(file_path)
                                                        conversation['line_number'] = line_num
                                                        conversation['category'] = category_name
                                                        low_quality_data[category_name].append(conversation)
                                                        self.stats['low_quality_conversations'] += 1
                                                        
                                                except json.JSONDecodeError:
                                                    continue
                                                    
                                except Exception as e:
                                    print(f"     ‚ö†Ô∏è Error procesando {file_path}: {e}")
                                    continue
            
        except Exception as e:
            print(f"   ‚ùå Error ejecutando adaptive_processor: {e}")
            import traceback
            traceback.print_exc()
        
        print(f"   ‚úÖ An√°lisis completado:")
        print(f"     üìä Conversaciones totales: {self.stats['total_conversations']:,}")
        print(f"     üìâ Baja calidad encontradas: {self.stats['low_quality_conversations']:,}")
        print(f"     ÔøΩ Categor√≠as con problemas: {len(low_quality_data)}")
        
        return dict(low_quality_data)
    
    def _analyze_problematic_patterns(self, low_quality_data: Dict[str, List[Dict]]) -> Dict[str, Any]:
        """Analiza patrones comunes en conversaciones de baja calidad separando fundamentales vs espec√≠ficas"""
        print("   üîç Analizando patrones problem√°ticos (fundamentales vs espec√≠ficas)...")
        
        patterns = {
            'by_category': {},
            'fundamental_issues': defaultdict(int),
            'specific_issues': defaultdict(int),
            'question_patterns': {
                'fundamental': defaultdict(int),
                'specific': defaultdict(int)
            },
            'answer_patterns': {
                'fundamental': defaultdict(int),
                'specific': defaultdict(int)
            },
            'quality_analysis': {
                'fundamental_below_09': 0,
                'specific_below_07': 0,
                'fundamental_avg_quality': 0.0,
                'specific_avg_quality': 0.0
            }
        }
        
        for category, conversations in low_quality_data.items():
            category_patterns = {
                'total_count': len(conversations),
                'fundamental_problems': 0,
                'specific_problems': 0,
                'avg_quality_score': 0,
                'fundamental_phrases': defaultdict(int),
                'specific_phrases': defaultdict(int),
                'structural_issues': {
                    'fundamental': defaultdict(int),
                    'specific': defaultdict(int)
                }
            }
            
            total_score = 0
            fundamental_scores = []
            specific_scores = []
            
            for conv in conversations:
                quality_score = conv.get('quality_score', 0)
                total_score += quality_score
                
                # Analizar tipo de pregunta (fundamental vs espec√≠fica)
                question = conv.get('question', '').lower()
                question_type = self._classify_question_type(question)
                
                if question_type == 'fundamental':
                    fundamental_scores.append(quality_score)
                    if quality_score < 0.9:
                        category_patterns['fundamental_problems'] += 1
                        patterns['quality_analysis']['fundamental_below_09'] += 1
                        self._analyze_fundamental_issues(conv, patterns['fundamental_issues'])
                        self._analyze_question_patterns(question, patterns['question_patterns']['fundamental'])
                else:
                    specific_scores.append(quality_score)
                    if quality_score < 0.7:
                        category_patterns['specific_problems'] += 1
                        patterns['quality_analysis']['specific_below_07'] += 1
                        self._analyze_specific_issues(conv, patterns['specific_issues'])
                        self._analyze_question_patterns(question, patterns['question_patterns']['specific'])
                
                # Analizar problemas estructurales
                self._analyze_structural_issues(conv, category_patterns['structural_issues'][question_type])
            
            if conversations:
                category_patterns['avg_quality_score'] = total_score / len(conversations)
                
            if fundamental_scores:
                patterns['quality_analysis']['fundamental_avg_quality'] = sum(fundamental_scores) / len(fundamental_scores)
                
            if specific_scores:
                patterns['quality_analysis']['specific_avg_quality'] = sum(specific_scores) / len(specific_scores)
            
            patterns['by_category'][category] = category_patterns
            self.stats['fundamental_patterns_identified'] += category_patterns['fundamental_problems']
            self.stats['specific_patterns_identified'] += category_patterns['specific_problems']
        
        print(f"   ‚úÖ Patrones fundamentales problem√°ticos: {self.stats['fundamental_patterns_identified']}")
        print(f"   ‚úÖ Patrones espec√≠ficos problem√°ticos: {self.stats['specific_patterns_identified']}")
        print(f"   üìä Calidad promedio fundamentales: {patterns['quality_analysis']['fundamental_avg_quality']:.3f}")
        print(f"   üìä Calidad promedio espec√≠ficas: {patterns['quality_analysis']['specific_avg_quality']:.3f}")
        
        return patterns
    
    def _classify_question_type(self, question: str) -> str:
        """Clasifica si una pregunta es fundamental o espec√≠fica"""
        fundamental_indicators = [
            'qu√© es', 'qui√©n es', 'cu√°l es', 'expl√≠came', 'explica',
            'definici√≥n', 'concepto', 'caracter√≠sticas principales',
            'importancia', 'significado', 'prop√≥sito', 'funci√≥n'
        ]
        
        specific_indicators = [
            'cu√°ndo', 'd√≥nde', 'c√≥mo', 'por qu√© espec√≠ficamente',
            'detalles', 'proceso', 'pasos', 'm√©todo', 't√©cnica',
            'ejemplo', 'caso', 'situaci√≥n', 'contexto espec√≠fico'
        ]
        
        question_lower = question.lower()
        
        fundamental_score = sum(1 for indicator in fundamental_indicators if indicator in question_lower)
        specific_score = sum(1 for indicator in specific_indicators if indicator in question_lower)
        
        return 'fundamental' if fundamental_score >= specific_score else 'specific'
    
    def _analyze_fundamental_issues(self, conversation: Dict, issues_counter: defaultdict):
        """Analiza problemas espec√≠ficos en preguntas fundamentales"""
        question = conversation.get('question', '')
        answer = conversation.get('answer', '')
        
        # Problemas comunes en preguntas fundamentales
        if len(question) < 20:
            issues_counter['question_too_short'] += 1
        if 'expl√≠came en detalle' not in question.lower() and len(answer) < 100:
            issues_counter['insufficient_detail'] += 1
        if not any(word in question.lower() for word in ['qu√©', 'cu√°l', 'qui√©n']):
            issues_counter['missing_fundamental_words'] += 1
        if '?' not in question:
            issues_counter['missing_question_mark'] += 1
    
    def _analyze_specific_issues(self, conversation: Dict, issues_counter: defaultdict):
        """Analiza problemas espec√≠ficos en preguntas espec√≠ficas"""
        question = conversation.get('question', '')
        answer = conversation.get('answer', '')
        
        # Problemas comunes en preguntas espec√≠ficas
        if len(question) < 15:
            issues_counter['question_too_short'] += 1
        if not any(word in question.lower() for word in ['c√≥mo', 'cu√°ndo', 'd√≥nde', 'por qu√©']):
            issues_counter['missing_specific_words'] += 1
        if len(answer) < 50:
            issues_counter['answer_too_brief'] += 1
        if 'ejemplo' not in question.lower() and 'por ejemplo' not in answer.lower():
            issues_counter['lacks_examples'] += 1
    
    def _analyze_question_patterns(self, question: str, patterns_counter: defaultdict):
        """Analiza patrones en las preguntas"""
        words = question.lower().split()
        
        # Contar palabras comunes
        for word in words:
            if len(word) > 3:  # Solo palabras significativas
                patterns_counter[word] += 1
        
        # Contar frases comunes
        common_phrases = ['qu√© es', 'cu√°l es', 'c√≥mo se', 'por qu√©', 'expl√≠came']
        for phrase in common_phrases:
            if phrase in question.lower():
                patterns_counter[f"phrase_{phrase.replace(' ', '_')}"] += 1
    
    def _analyze_structural_issues(self, conversation: Dict, issues_counter: defaultdict):
        """Analiza problemas estructurales en la conversaci√≥n"""
        question = conversation.get('question', '')
        answer = conversation.get('answer', '')
        
        # Problemas estructurales
        if not question.strip():
            issues_counter['empty_question'] += 1
        if not answer.strip():
            issues_counter['empty_answer'] += 1
        if question == answer:
            issues_counter['question_equals_answer'] += 1
        if len(answer.split()) < 10:
            issues_counter['answer_too_short'] += 1
                
                question = conv.get('question', '')
                answer = conv.get('answer', '')
                
                # An√°lisis de longitud
                if len(answer) < 50:
                    category_patterns['length_issues']['too_short'] += 1
                    patterns['common_issues']['respuesta_muy_corta'] += 1
                elif len(answer) > 1000:
                    category_patterns['length_issues']['too_long'] += 1
                    patterns['common_issues']['respuesta_muy_larga'] += 1
                
                # An√°lisis de frases problem√°ticas
                problematic_phrases = [
                    'es un concepto',
                    'se define como',
                    'corresponde a',
                    'se refiere a',
                    'no se puede',
                    'informaci√≥n no disponible'
                ]
                
                for phrase in problematic_phrases:
                    if phrase in answer.lower():
                        category_patterns['common_phrases'][phrase] += 1
                        patterns['linguistic_issues'][phrase] += 1
                
                # An√°lisis de patrones de pregunta
                if question.startswith('¬øQu√© es'):
                    patterns['question_patterns']['definicional'] += 1
                elif question.startswith('¬øC√≥mo'):
                    patterns['question_patterns']['procedimental'] += 1
                elif question.startswith('¬øCu√°l'):
                    patterns['question_patterns']['selectivo'] += 1
                
                # Problemas estructurales
                if not answer.strip().endswith(('.', '!', '?')):
                    category_patterns['structural_issues']['sin_puntuacion_final'] += 1
                    patterns['common_issues']['sin_puntuacion_final'] += 1
                
                if answer.count('\n') == 0 and len(answer) > 200:
                    category_patterns['structural_issues']['sin_parrafos'] += 1
                    patterns['common_issues']['sin_estructura_parrafos'] += 1
            
            if conversations:
                category_patterns['avg_quality_score'] = total_score / len(conversations)
            
            patterns['by_category'][category] = category_patterns
            self.stats['patterns_identified'] += len(category_patterns['common_phrases'])
        
        print(f"   ‚úÖ Patrones identificados: {self.stats['patterns_identified']}")
        print(f"   üìä Issues m√°s comunes:")
        for issue, count in sorted(patterns['common_issues'].items(), key=lambda x: x[1], reverse=True)[:5]:
            print(f"      ‚Ä¢ {issue}: {count:,} casos")
        
        return patterns
    
    def _generate_optimized_patterns(self, problematic_patterns: Dict[str, Any]) -> Dict[str, Any]:
        """Genera patrones optimizados para corregir problemas identificados"""
        print("   ‚öôÔ∏è Generando patrones optimizados para fundamentales y espec√≠ficas...")
        
        optimized_patterns = {
            'fundamental_improvements': {},
            'specific_improvements': {},
            'universal_fixes': {},
            'category_specific_fixes': {}
        }
        
        # PATRONES OPTIMIZADOS PARA PREGUNTAS FUNDAMENTALES
        fundamental_issues = problematic_patterns.get('fundamental_issues', {})
        optimized_patterns['fundamental_improvements'] = {
            'templates': [
                "¬øQu√© es {topic} y cu√°les son sus caracter√≠sticas principales?",
                "Expl√≠came en detalle {topic} y su importancia.",
                "¬øCu√°l es la definici√≥n completa de {topic} y por qu√© es relevante?",
                "¬øQui√©n o qu√© es {topic} y qu√© funci√≥n cumple?",
                "Describe {topic} de manera comprehensiva incluyendo sus aspectos fundamentales."
            ],
            'quality_enhancements': {
                'minimum_answer_length': 150,
                'required_elements': ['definici√≥n', 'caracter√≠sticas', 'importancia', 'contexto'],
                'quality_threshold': 0.9,
                'mandatory_detail_question': True
            },
            'fixes_for_issues': {}
        }
        
        # Fixes espec√≠ficos para problemas fundamentales
        if fundamental_issues.get('question_too_short', 0) > 0:
            optimized_patterns['fundamental_improvements']['fixes_for_issues']['short_questions'] = {
                'strategy': 'expand_with_context',
                'templates': [
                    "¬øQu√© es {topic} en el contexto de {category} y cu√°les son sus caracter√≠sticas principales?",
                    "Expl√≠came en detalle qu√© significa {topic} y por qu√© es importante."
                ]
            }
        
        if fundamental_issues.get('insufficient_detail', 0) > 0:
            optimized_patterns['fundamental_improvements']['fixes_for_issues']['insufficient_detail'] = {
                'strategy': 'force_comprehensive_answers',
                'requirements': ['definici√≥n completa', 'ejemplos', 'contexto hist√≥rico', 'relevancia actual']
            }
        
        # PATRONES OPTIMIZADOS PARA PREGUNTAS ESPEC√çFICAS
        specific_issues = problematic_patterns.get('specific_issues', {})
        optimized_patterns['specific_improvements'] = {
            'templates': [
                "¬øC√≥mo se implementa espec√≠ficamente {topic} en {context}?",
                "¬øCu√°ndo y d√≥nde se utiliza {topic} de manera pr√°ctica?",
                "¬øPor qu√© es importante {specific_aspect} de {topic}?",
                "¬øQu√© pasos espec√≠ficos se siguen para {action} en {topic}?",
                "Proporciona ejemplos concretos de {topic} en {application_area}."
            ],
            'quality_enhancements': {
                'minimum_answer_length': 80,
                'required_elements': ['ejemplos espec√≠ficos', 'contexto pr√°ctico', 'detalles t√©cnicos'],
                'quality_threshold': 0.7,
                'examples_required': True
            },
            'fixes_for_issues': {}
        }
        
        # Fixes espec√≠ficos para problemas espec√≠ficos
        if specific_issues.get('lacks_examples', 0) > 0:
            optimized_patterns['specific_improvements']['fixes_for_issues']['missing_examples'] = {
                'strategy': 'force_examples',
                'requirements': ['al menos 2 ejemplos concretos', 'casos de uso espec√≠ficos']
            }
        
        if specific_issues.get('answer_too_brief', 0) > 0:
            optimized_patterns['specific_improvements']['fixes_for_issues']['brief_answers'] = {
                'strategy': 'expand_with_details',
                'requirements': ['detalles t√©cnicos', 'pasos espec√≠ficos', 'contexto de aplicaci√≥n']
            }
        
        # FIXES UNIVERSALES (aplican a ambos tipos)
        common_issues = problematic_patterns.get('quality_analysis', {})
        optimized_patterns['universal_fixes'] = {
            'structural_improvements': {
                'ensure_question_marks': True,
                'minimum_paragraph_structure': True,
                'proper_punctuation': True,
                'logical_flow': True
            },
            'content_improvements': {
                'avoid_repetition': True,
                'use_varied_vocabulary': True,
                'include_transitions': True,
                'maintain_coherence': True
            }
        }
        
        # FIXES POR CATEGOR√çA
        for category, patterns in problematic_patterns.get('by_category', {}).items():
            category_fixes = {
                'fundamental_focus': [],
                'specific_focus': [],
                'category_templates': []
            }
            
            # Determinar enfoque por categor√≠a
            if patterns.get('fundamental_problems', 0) > patterns.get('specific_problems', 0):
                category_fixes['fundamental_focus'] = [
                    f"√ânfasis en definiciones claras para {category}",
                    f"Respuestas m√°s comprehensivas para conceptos de {category}",
                    f"Mayor detalle en explicaciones fundamentales de {category}"
                ]
            else:
                category_fixes['specific_focus'] = [
                    f"M√°s ejemplos pr√°cticos para {category}",
                    f"Detalles t√©cnicos espec√≠ficos de {category}",
                    f"Casos de uso concretos en {category}"
                ]
            
            optimized_patterns['category_specific_fixes'][category] = category_fixes
        
        print(f"   ‚úÖ Patrones fundamentales generados: {len(optimized_patterns['fundamental_improvements']['templates'])}")
        print(f"   ‚úÖ Patrones espec√≠ficos generados: {len(optimized_patterns['specific_improvements']['templates'])}")
        print(f"   ‚úÖ Fixes por categor√≠a: {len(optimized_patterns['category_specific_fixes'])}")
        
        return optimized_patterns
        """Genera patrones optimizados para corregir problemas identificados"""
        print("   ‚öôÔ∏è Generando patrones optimizados...")
        
        optimized_patterns = {
            'improved_templates': {},
            'quality_filters': {},
            'enhancement_rules': {},
            'fallback_strategies': {}
        }
        
        # Generar templates mejorados por categor√≠a
        for category, patterns in problematic_patterns['by_category'].items():
            improved_template = {
                'category': category,
                'min_length': 100,  # Evitar respuestas muy cortas
                'max_length': 800,  # Evitar respuestas muy largas
                'required_structure': {
                    'introduction': True,
                    'main_content': True,
                    'conclusion': True
                },
                'avoid_phrases': list(patterns['common_phrases'].keys()),
                'quality_enhancements': []
            }
            
            # Reglas espec√≠ficas basadas en problemas encontrados
            if patterns['length_issues']['too_short'] > 10:
                improved_template['quality_enhancements'].append({
                    'type': 'length_expansion',
                    'target': 'increase_detail',
                    'method': 'add_examples_and_context'
                })
            
            if patterns['structural_issues']['sin_puntuacion_final'] > 5:
                improved_template['quality_enhancements'].append({
                    'type': 'punctuation_fix',
                    'target': 'ensure_proper_ending',
                    'method': 'add_final_punctuation'
                })
            
            if patterns['structural_issues']['sin_parrafos'] > 5:
                improved_template['quality_enhancements'].append({
                    'type': 'structure_improvement',
                    'target': 'add_paragraphs',
                    'method': 'break_into_logical_sections'
                })
            
            optimized_patterns['improved_templates'][category] = improved_template
        
        # Filtros de calidad generales
        optimized_patterns['quality_filters'] = {
            'minimum_quality_score': 0.7,
            'required_elements': ['proper_punctuation', 'adequate_length', 'relevant_content'],
            'prohibited_patterns': list(problematic_patterns['linguistic_issues'].keys()),
            'structural_requirements': {
                'min_sentences': 3,
                'max_sentences': 15,
                'paragraph_breaks': True
            }
        }
        
        # Reglas de mejora
        optimized_patterns['enhancement_rules'] = {
            'phrase_replacement': {
                'es un concepto': 'representa una idea fundamental que',
                'se define como': 'puede entenderse como',
                'corresponde a': 'hace referencia a',
                'se refiere a': 'alude espec√≠ficamente a'
            },
            'structure_templates': {
                'definition': '{topic} {enhanced_definition}. {detailed_explanation}. {practical_examples}.',
                'explanation': '{topic} {process_description}. {step_by_step}. {final_summary}.',
                'comparison': '{topic} {comparison_intro}. {similarities}. {differences}. {conclusion}.'
            }
        }
        
        print(f"   ‚úÖ Templates optimizados: {len(optimized_patterns['improved_templates'])}")
        print(f"   üéØ Filtros de calidad: {len(optimized_patterns['quality_filters'])}")
        
        return optimized_patterns
    
    def _generate_improved_questions(self, optimized_patterns: Dict[str, Any]) -> Dict[str, List[Dict]]:
        """Genera preguntas mejoradas usando los patrones optimizados separando fundamentales y espec√≠ficas"""
        print("   üìù Generando preguntas mejoradas (fundamentales y espec√≠ficas)...")
        
        improved_questions = {
            'fundamental': [],
            'specific': [],
            'by_category': {}
        }
        
        # Usar el ContentManager mejorado para generar preguntas
        for category in ['ciencia', 'historia', 'tecnologia', 'arte', 'deportes']:
            print(f"     üìÇ Procesando categor√≠a: {category}")
            
            # Generar art√≠culo de ejemplo para la categor√≠a
            sample_article = {
                'title': f"Ejemplo de {category}",
                'content': f"Contenido de ejemplo para la categor√≠a {category} que permite generar preguntas fundamentales y espec√≠ficas de alta calidad.",
                'url': f"example_{category}.html"
            }
            
            category_improved = {
                'fundamental': [],
                'specific': []
            }
            
            try:
                # Usar el content_manager con los nuevos par√°metros
                conversations = self.content_manager.generate_enhanced_questions(
                    article=sample_article,
                    category=category
                )
                
                for conv in conversations:
                    question_type = self._classify_question_type(conv.get('question', ''))
                    quality_score = conv.get('quality_score', 0.0)
                    
                    # Aplicar mejoras seg√∫n el tipo
                    if question_type == 'fundamental' and quality_score >= 0.9:
                        improved_questions['fundamental'].append(conv)
                        category_improved['fundamental'].append(conv)
                        self.stats['improved_fundamental_questions'] += 1
                    elif question_type == 'specific' and quality_score >= 0.7:
                        improved_questions['specific'].append(conv)
                        category_improved['specific'].append(conv)
                        self.stats['improved_specific_questions'] += 1
                
                improved_questions['by_category'][category] = category_improved
                
                print(f"       ‚úÖ Fundamentales: {len(category_improved['fundamental'])}")
                print(f"       ‚úÖ Espec√≠ficas: {len(category_improved['specific'])}")
                
            except Exception as e:
                print(f"       ‚ö†Ô∏è Error procesando {category}: {e}")
                continue
        
        print(f"   ‚úÖ Total fundamentales mejoradas: {len(improved_questions['fundamental'])}")
        print(f"   ‚úÖ Total espec√≠ficas mejoradas: {len(improved_questions['specific'])}")
        
        return improved_questions
            
            improved_questions[category] = category_questions
            self.stats['categories_processed'] += 1
            
            print(f"     üìÇ {category}: {len(category_questions)} preguntas inteligentes generadas")
        
        print(f"   ‚úÖ Total preguntas mejoradas: {self.stats['improved_questions_generated']}")
        
        # Guardar preguntas inteligentes en archivos separados
        self.intelligent_generator.save_questions_to_file(
            intelligent_questions, 
            str(self.output_dir / "intelligent_questions")
        )
        
        return improved_questions
    
    def _convert_intelligent_to_improved(self, question_data: Dict, category: str, 
                                       category_config: Dict, optimized_patterns: Dict) -> Optional[Dict]:
        """Convierte pregunta inteligente a formato mejorado con respuesta"""
        try:
            # Usar template de la pregunta inteligente
            question_template = question_data.get('template', '')
            question_type = question_data.get('type', 'general')
            
            # Crear topic placeholder espec√≠fico para la categor√≠a
            topic_placeholder = "{topic_" + category.replace('-', '_') + "}"
            question = question_template.replace("{title}", topic_placeholder)
            
            # Generar respuesta mejorada basada en el tipo de pregunta
            enhanced_answer = self._generate_enhanced_answer_intelligent(
                question_data, category, category_config, optimized_patterns
            )
            
            improved_question = {
                'question': question,
                'answer': enhanced_answer,
                'question_type': question_type,
                'category': category,
                'quality_score': question_data.get('final_rank_score', 0.8),
                'enhancement_applied': True,
                'intelligent_generation': True,
                'ranking_details': question_data.get('ranking_details', {}),
                'specificity': question_data.get('specificity', 'medium'),
                'applicability': question_data.get('applicability', 'medium'),
                'generation_method': question_data.get('generation_method', 'intelligent'),
                'template_source': 'intelligent_question_generator',
                'improvement_timestamp': datetime.now().isoformat(),
                'metadata': {
                    'original_template': question_template,
                    'category_config': category_config.get('keywords', [])[:5],  # Solo primeras 5 keywords
                    'quality_enhancements': ['intelligent_generation', 'category_specific', 'ranked_selection']
                }
            }
            
            return improved_question
            
        except Exception as e:
            print(f"     ‚ö†Ô∏è Error convirtiendo pregunta para {category}: {e}")
            return None
    
    def _generate_enhanced_answer_intelligent(self, question_data: Dict, category: str, 
                                            category_config: Dict, optimized_patterns: Dict) -> str:
        """Genera respuesta mejorada basada en pregunta inteligente"""
        question_type = question_data.get('type', 'general')
        specificity = question_data.get('specificity', 'medium')
        
        # Templates de respuesta por tipo de pregunta
        answer_templates = {
            'definitional': f"{{topic_{category.replace('-', '_')}}} es {{concepto_principal}} que se caracteriza por {{caracteristicas_clave}}. En el contexto de {category}, {{explicacion_detallada}} y presenta {{aspectos_relevantes}}.",
            
            'functional': f"{{topic_{category.replace('-', '_')}}} funciona mediante {{proceso_principal}} que involucra {{pasos_clave}}. El mecanismo incluye {{componentes}} y se basa en {{principios_fundamentales}}.",
            
            'technical_specs': f"Las especificaciones t√©cnicas de {{topic_{category.replace('-', '_')}}} incluyen {{especificaciones_principales}}. Los par√°metros clave son {{parametros}} con {{valores_tipicos}}.",
            
            'historical_context': f"{{topic_{category.replace('-', '_')}}} ocurri√≥ en {{periodo_historico}} durante {{contexto_temporal}}. Los antecedentes incluyen {{causas}} y las consecuencias fueron {{efectos}}.",
            
            'cultural_meaning': f"En t√©rminos culturales, {{topic_{category.replace('-', '_')}}} representa {{significado_cultural}} y tiene {{importancia_social}}. Se manifiesta atrav√©s de {{expresiones}} y {{tradiciones}}.",
            
            'importance': f"La importancia de {{topic_{category.replace('-', '_')}}} radica en {{relevancia_principal}} para {category}. Su impacto se observa en {{areas_impacto}} y {{beneficios_clave}}.",
            
            'comparative': f"{{topic_{category.replace('-', '_')}}} se diferencia de {{conceptos_similares}} en {{diferencias_clave}}. Sus ventajas incluyen {{ventajas}} mientras que {{elementos_distintivos}}."
        }
        
        # Seleccionar template apropiado
        template = answer_templates.get(question_type, answer_templates['definitional'])
        
        # Agregar elementos de calidad basados en especificidad
        if specificity == 'high':
            template += " Espec√≠ficamente, {detalles_especificos} y {aspectos_tecnicos}."
        elif specificity == 'medium':
            template += " Adem√°s, {informacion_adicional} y {contexto_relevante}."
        
        # Agregar elementos de aplicabilidad
        applicability = question_data.get('applicability', 'medium')
        if 'universal' in applicability:
            template += " Este concepto es aplicable universalmente en {aplicaciones_universales}."
        
        return template
    
    def _create_improved_question(self, category: str, question_type: str, 
                                template: Dict, category_config: Dict) -> Optional[Dict]:
        """Crea una pregunta mejorada individual"""
        try:
            # Templates mejorados por tipo
            question_templates = {
                'definitional': [
                    "¬øC√≥mo se puede explicar en detalle {topic}?",
                    "¬øQu√© caracter√≠sticas fundamentales define {topic}?",
                    "¬øDe qu√© manera {topic} se manifiesta en su contexto?"
                ],
                'explanatory': [
                    "¬øCu√°l es el proceso completo detr√°s de {topic}?",
                    "¬øC√≥mo funciona espec√≠ficamente {topic}?",
                    "¬øQu√© mecanismos intervienen en {topic}?"
                ],
                'analytical': [
                    "¬øQu√© factores influyen en el desarrollo de {topic}?",
                    "¬øCu√°les son las implicaciones de {topic}?",
                    "¬øQu√© relaciones establece {topic} con otros elementos?"
                ],
                'comparative': [
                    "¬øEn qu√© se diferencia {topic} de conceptos similares?",
                    "¬øQu√© ventajas presenta {topic} comparado con alternativas?",
                    "¬øC√≥mo se relaciona {topic} con otros elementos de su categor√≠a?"
                ]
            }
            
            # Seleccionar template aleatorio
            import random
            templates = question_templates.get(question_type, question_templates['definitional'])
            selected_template = random.choice(templates)
            
            # Crear topic placeholder
            topic_placeholder = "{topic_" + category.replace('-', '_') + "}"
            question = selected_template.replace("{topic}", topic_placeholder)
            
            # Generar respuesta mejorada usando template
            answer_template = template.get('quality_enhancements', [])
            enhanced_answer = self._generate_enhanced_answer(question_type, category, template)
            
            improved_question = {
                'question': question,
                'answer': enhanced_answer,
                'question_type': question_type,
                'category': category,
                'quality_score': 0.8,  # Score objetivo alto
                'enhancement_applied': True,
                'template_used': 'optimized_' + question_type,
                'generation_method': 'batch_optimization_qr',
                'target_quality_threshold': 0.7,
                'timestamp': datetime.now().isoformat()
            }
            
            return improved_question
            
        except Exception as e:
            print(f"     ‚ö†Ô∏è Error creando pregunta mejorada: {e}")
            return None
    
    def _generate_enhanced_answer(self, question_type: str, category: str, template: Dict) -> str:
        """Genera respuesta mejorada evitando patrones problem√°ticos"""
        
        # Obtener frases a evitar
        avoid_phrases = template.get('avoid_phrases', [])
        
        # Templates de respuesta mejorada
        enhanced_templates = {
            'definitional': (
                "Este concepto representa un elemento fundamental en {category} que abarca m√∫ltiples dimensiones. "
                "Su comprensi√≥n requiere analizar tanto sus caracter√≠sticas intr√≠nsecas como su contexto de aplicaci√≥n. "
                "Los aspectos m√°s relevantes incluyen su funci√≥n espec√≠fica, sus relaciones con otros elementos "
                "y su importancia dentro del marco conceptual m√°s amplio."
            ),
            'explanatory': (
                "El proceso involucra una secuencia de etapas interconectadas que se desarrollan de manera sistem√°tica. "
                "Inicialmente, se establecen las condiciones necesarias, seguido por la implementaci√≥n de los mecanismos "
                "espec√≠ficos. Durante el desarrollo, diversos factores contribuyen al resultado final, "
                "creando un conjunto integrado de outcomes observables."
            ),
            'analytical': (
                "El an√°lisis revela m√∫ltiples dimensiones que interact√∫an de manera compleja. "
                "Los factores determinantes incluyen elementos contextuales, estructurales y funcionales "
                "que configuran su comportamiento. Las implicaciones se extienden m√°s all√° del √°mbito inmediato, "
                "generando efectos en sistemas relacionados y estableciendo patrones de influencia duraderos."
            ),
            'comparative': (
                "La comparaci√≥n con elementos similares destaca caracter√≠sticas distintivas significativas. "
                "Las similitudes se centran en aspectos estructurales b√°sicos, mientras que las diferencias "
                "emergen en la implementaci√≥n espec√≠fica y los resultados obtenidos. "
                "Esta diferenciaci√≥n proporciona ventajas √∫nicas en contextos particulares."
            )
        }
        
        base_answer = enhanced_templates.get(question_type, enhanced_templates['definitional'])
        
        # Personalizar para la categor√≠a
        category_name = category.replace('-', ' ').replace('_', ' ').title()
        enhanced_answer = base_answer.replace('{category}', category_name)
        
        # Asegurar que no contiene frases problem√°ticas
        for phrase in avoid_phrases:
            if phrase in enhanced_answer.lower():
                # Reemplazar con versi√≥n mejorada
                improvements = {
                    'es un concepto': 'representa un elemento',
                    'se define como': 'puede caracterizarse como',
                    'corresponde a': 'hace referencia a',
                    'se refiere a': 'alude espec√≠ficamente a'
                }
                replacement = improvements.get(phrase, phrase.replace('es un', 'constituye un'))
                enhanced_answer = enhanced_answer.replace(phrase, replacement)
        
        return enhanced_answer
    
    def _validate_improvements(self, improved_questions: Dict[str, List[Dict]]) -> Dict[str, Any]:
        """Valida que las mejoras cumplan los criterios de calidad"""
        print("   üß™ Validando mejoras generadas...")
        
        validation_results = {
            'total_validated': 0,
            'passed_validation': 0,
            'quality_scores': [],
            'issues_found': [],
            'validation_summary': {}
        }
        
        for category, questions in improved_questions.items():
            category_validation = {
                'total': len(questions),
                'passed': 0,
                'avg_quality': 0,
                'issues': []
            }
            
            total_quality = 0
            
            for question in questions:
                validation_results['total_validated'] += 1
                
                # Validar usando formation_system
                validation_result = self.formation_system.validate_conversation(question)
                
                quality_score = validation_result.get('quality_score', 0)
                is_valid = validation_result.get('is_valid', False)
                
                total_quality += quality_score
                validation_results['quality_scores'].append(quality_score)
                
                if is_valid and quality_score >= 0.7:
                    validation_results['passed_validation'] += 1
                    category_validation['passed'] += 1
                else:
                    issues = validation_result.get('issues', [])
                    validation_results['issues_found'].extend(issues)
                    category_validation['issues'].extend(issues)
            
            if questions:
                category_validation['avg_quality'] = total_quality / len(questions)
            
            validation_results['validation_summary'][category] = category_validation
        
        pass_rate = (validation_results['passed_validation'] / validation_results['total_validated']) * 100 if validation_results['total_validated'] > 0 else 0
        avg_quality = sum(validation_results['quality_scores']) / len(validation_results['quality_scores']) if validation_results['quality_scores'] else 0
        
        print(f"   ‚úÖ Validaciones: {validation_results['total_validated']}")
        print(f"   üéØ Aprobadas: {validation_results['passed_validation']} ({pass_rate:.1f}%)")
        print(f"   üìä Calidad promedio: {avg_quality:.3f}")
        
        return validation_results
    
    def _generate_fundamentals_training(self, optimized_patterns: Dict[str, Any], 
                                      improved_questions: Dict[str, List[Dict]]):
        """Genera archivos en carpeta fundamentals_training con preguntas inteligentes"""
        print("   üíæ Generando archivos fundamentals_training con sistema inteligente...")
        
        # Crear fundamental.jsonl principal con informaci√≥n del sistema inteligente
        fundamental_path = self.output_dir / "fundamental.jsonl"
        
        with open(fundamental_path, 'w', encoding='utf-8') as f:
            # Agregar configuraciones optimizadas
            config_entry = {
                'type': 'intelligent_optimized_configuration',
                'data': {
                    'quality_threshold': self.quality_threshold,
                    'optimization_patterns': optimized_patterns,
                    'intelligent_system': {
                        'questions_per_category': self.intelligent_generator.questions_per_category,
                        'base_questions_count': self.intelligent_generator.base_questions_count,
                        'specific_questions_count': self.intelligent_generator.specific_questions_count,
                        'ranking_weights': self.intelligent_generator.ranking_weights
                    },
                    'generation_timestamp': datetime.now().isoformat(),
                    'version': '3.0-intelligent-optimized'
                },
                'quality_score': 0.95,  # Calidad alta con sistema inteligente
                'timestamp': datetime.now().isoformat()
            }
            json.dump(config_entry, f, ensure_ascii=False)
            f.write('\n')
        
        # Crear archivos por categor√≠a con preguntas inteligentes mejoradas
        categories_processed = 0
        questions_files_created = 0
        patterns_files_created = 0
        
        for category, questions in improved_questions.items():
            # Archivo de preguntas inteligentes mejoradas
            questions_file = self.output_dir / f"questions_intelligent.{category}.jsonl"
            
            with open(questions_file, 'w', encoding='utf-8') as f:
                for question in questions:
                    # Agregar metadata del sistema inteligente
                    question['system_version'] = '3.0-intelligent'
                    question['batch_optimization_qr'] = True
                    question['intelligent_enhancement'] = True
                    
                    json.dump(question, f, ensure_ascii=False)
                    f.write('\n')
            
            questions_files_created += 1
            
            # Archivo de patrones optimizados para esta categor√≠a
            if category in optimized_patterns['improved_templates']:
                pattern_file = self.output_dir / f"patterns_intelligent.{category}.jsonl"
                
                with open(pattern_file, 'w', encoding='utf-8') as f:
                    pattern_entry = {
                        'type': 'intelligent_optimized_pattern',
                        'category': category,
                        'data': optimized_patterns['improved_templates'][category],
                        'intelligent_system_applied': True,
                        'questions_generated': len(questions),
                        'avg_quality_score': sum(q.get('quality_score', 0.8) for q in questions) / len(questions) if questions else 0.8,
                        'timestamp': datetime.now().isoformat()
                    }
                    json.dump(pattern_entry, f, ensure_ascii=False)
                    f.write('\n')
                
                patterns_files_created += 1
            
            categories_processed += 1
        
        # Crear archivo de estad√≠sticas del sistema inteligente
        stats_file = self.output_dir / "intelligent_system_stats.json"
        
        intelligent_stats = {
            'system_version': '3.0-intelligent-batch-optimization',
            'processing_timestamp': datetime.now().isoformat(),
            'configuration': {
                'questions_per_category': self.intelligent_generator.questions_per_category,
                'base_questions_count': self.intelligent_generator.base_questions_count,
                'specific_questions_count': self.intelligent_generator.specific_questions_count,
                'quality_threshold': self.quality_threshold
            },
            'processing_results': {
                'categories_processed': categories_processed,
                'questions_files_created': questions_files_created,
                'patterns_files_created': patterns_files_created,
                'total_questions_generated': sum(len(q) for q in improved_questions.values()),
                'avg_questions_per_category': sum(len(q) for q in improved_questions.values()) / len(improved_questions) if improved_questions else 0
            },
            'ranking_system': self.intelligent_generator.ranking_weights,
            'quality_improvements': {
                'intelligent_generation': True,
                'category_specific_questions': True,
                'ranking_based_selection': True,
                'base_plus_specific_pattern': True
            }
        }
        
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(intelligent_stats, f, ensure_ascii=False, indent=2)
        
        print(f"   ‚úÖ Archivos generados en: {self.output_dir}")
        print(f"     üìÑ fundamental.jsonl (configuraci√≥n inteligente)")
        print(f"     üìÑ {questions_files_created} questions_intelligent.{'{category}'}.jsonl")
        print(f"     üìÑ {patterns_files_created} patterns_intelligent.{'{category}'}.jsonl")
        print(f"     üìä intelligent_system_stats.json")
        print(f"     üéØ {sum(len(q) for q in improved_questions.values())} preguntas inteligentes totales")
    
    def _generate_reports(self, low_quality_data: Dict, optimized_patterns: Dict, 
                         validation_results: Dict):
        """Genera reportes detallados del proceso de optimizaci√≥n"""
        print("   üìä Generando reportes...")
        
        # Reporte principal
        report_path = self.output_dir / "optimization_report.md"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# üöÄ REPORTE DE OPTIMIZACI√ìN BATCH QR\n\n")
            f.write(f"**Generado:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"**Umbral de calidad:** {self.quality_threshold}\n\n")
            
            # Estad√≠sticas generales
            f.write("## üìä ESTAD√çSTICAS GENERALES\n\n")
            f.write("| M√©trica | Valor |\n")
            f.write("|---------|-------|\n")
            for key, value in self.stats.items():
                display_key = key.replace('_', ' ').title()
                if isinstance(value, float):
                    f.write(f"| {display_key} | {value:.2f} |\n")
                else:
                    f.write(f"| {display_key} | {value:,} |\n")
            
            # An√°lisis por categor√≠a
            f.write("\n## üìÇ AN√ÅLISIS POR CATEGOR√çA\n\n")
            for category, conversations in low_quality_data.items():
                f.write(f"### {category.replace('-', ' ').title()}\n")
                f.write(f"- **Conversaciones de baja calidad:** {len(conversations):,}\n")
                
                if category in validation_results['validation_summary']:
                    val_data = validation_results['validation_summary'][category]
                    f.write(f"- **Preguntas mejoradas generadas:** {val_data['total']}\n")
                    f.write(f"- **Calidad promedio mejorada:** {val_data['avg_quality']:.3f}\n")
                    f.write(f"- **Tasa de aprobaci√≥n:** {(val_data['passed']/val_data['total']*100):.1f}%\n")
                f.write("\n")
            
            # Patrones optimizados
            f.write("## ‚öôÔ∏è PATRONES OPTIMIZADOS\n\n")
            templates_count = len(optimized_patterns.get('improved_templates', {}))
            f.write(f"- **Templates mejorados:** {templates_count}\n")
            f.write(f"- **Filtros de calidad:** {len(optimized_patterns.get('quality_filters', {}))}\n")
            f.write(f"- **Reglas de mejora:** {len(optimized_patterns.get('enhancement_rules', {}))}\n")
            
            # Validaci√≥n
            f.write("\n## üß™ RESULTADOS DE VALIDACI√ìN\n\n")
            total_val = validation_results['total_validated']
            passed_val = validation_results['passed_validation']
            avg_quality = sum(validation_results['quality_scores']) / len(validation_results['quality_scores']) if validation_results['quality_scores'] else 0
            
            f.write(f"- **Total validado:** {total_val:,}\n")
            f.write(f"- **Aprobado:** {passed_val:,} ({(passed_val/total_val*100):.1f}%)\n")
            f.write(f"- **Calidad promedio:** {avg_quality:.3f}\n")
            
            # Archivos generados
            f.write("\n## üìÅ ARCHIVOS GENERADOS\n\n")
            f.write(f"```\n")
            f.write(f"{self.output_dir}/\n")
            f.write(f"‚îú‚îÄ‚îÄ fundamental.jsonl\n")
            f.write(f"‚îú‚îÄ‚îÄ optimization_report.md\n")
            
            for category in low_quality_data.keys():
                f.write(f"‚îú‚îÄ‚îÄ questions_improved.{category}.jsonl\n")
                f.write(f"‚îú‚îÄ‚îÄ patterns_optimized.{category}.jsonl\n")
            
            f.write(f"‚îî‚îÄ‚îÄ low_quality_patterns/\n")
            f.write(f"```\n")
        
        # Reporte de estad√≠sticas JSON
        stats_path = self.output_dir / "optimization_stats.json"
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump({
                'execution_summary': self.stats,
                'validation_results': validation_results,
                'optimization_patterns': optimized_patterns,
                'timestamp': datetime.now().isoformat()
            }, f, ensure_ascii=False, indent=2)
        
        print(f"   ‚úÖ Reportes generados:")
        print(f"     üìÑ {report_path}")
        print(f"     üìÑ {stats_path}")


def main():
    """Funci√≥n principal para ejecutar optimizaci√≥n batch con data_test_ultra_hybrid"""
    
    print("üöÄ BATCH OPTIMIZATION QR - SISTEMA DE OPTIMIZACI√ìN")
    print("=" * 60)
    print("üìÇ Usando dataset de prueba: data_test_ultra_hybrid")
    print("üìã Configuraci√≥n: 5 fundamentales + 3 espec√≠ficas")
    print("=" * 60)
    
    # Crear instancia del optimizador usando data_test_ultra_hybrid
    optimizer = BatchOptimizationQR(
        source_dir="data_test_ultra_hybrid",  # Dataset peque√±o de prueba
        output_dir="test_output_batch_optimization",
        quality_threshold=0.6,
        fundamental_questions=5,
        specific_questions=3
    )
    
    try:
        # Ejecutar pipeline completo
        results = optimizer.run_optimization_pipeline()
        
        print(f"\nüéâ OPTIMIZACI√ìN COMPLETADA EXITOSAMENTE")
        print(f"üìä Estad√≠sticas finales:")
        for key, value in results.items():
            if isinstance(value, dict):
                print(f"   ‚Ä¢ {key.replace('_', ' ').title()}:")
                for k, v in value.items():
                    print(f"     - {k}: {v}")
            else:
                print(f"   ‚Ä¢ {key.replace('_', ' ').title()}: {value:,}")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå ERROR EN OPTIMIZACI√ìN: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    print("üöÄ BATCH OPTIMIZATION QR - Sistema Mejorado")
    print("=" * 60)
    
    # Crear el optimizador con par√°metros mejorados
    optimizer = BatchOptimizationQR(
        source_dir="data_conversations_complete",
        output_dir="fundamentals_training",
        quality_threshold=0.6,
        fundamental_questions=5,
        specific_questions=3
    )
    
    try:
        # Ejecutar el pipeline de optimizaci√≥n
        results = optimizer.run_optimization_pipeline()
        
        print("\nüìä RESULTADOS DEL PROCESO:")
        print("=" * 40)
        print(f"‚úÖ Total conversaciones analizadas: {results.get('total_conversations', 0):,}")
        print(f"üìâ Conversaciones de baja calidad: {results.get('low_quality_conversations', 0):,}")
        print(f"üìã Patrones fundamentales identificados: {results.get('fundamental_patterns_identified', 0)}")
        print(f"üéØ Patrones espec√≠ficos identificados: {results.get('specific_patterns_identified', 0)}")
        print(f"üí° Preguntas fundamentales mejoradas: {results.get('improved_fundamental_questions', 0)}")
        print(f"üéØ Preguntas espec√≠ficas mejoradas: {results.get('improved_specific_questions', 0)}")
        print(f"üìÇ Categor√≠as procesadas: {results.get('categories_processed', 0)}")
        print(f"‚è±Ô∏è Tiempo de procesamiento: {results.get('processing_time', 0):.2f}s")
        
        quality_improvements = results.get('quality_improvements', {})
        if quality_improvements:
            print(f"\nüìà MEJORAS DE CALIDAD:")
            print(f"   Fundamentales: {quality_improvements.get('fundamental_avg_before', 0):.3f} ‚Üí {quality_improvements.get('fundamental_avg_after', 0):.3f}")
            print(f"   Espec√≠ficas: {quality_improvements.get('specific_avg_before', 0):.3f} ‚Üí {quality_improvements.get('specific_avg_after', 0):.3f}")
        
        print(f"\nüéâ OPTIMIZACI√ìN COMPLETADA EXITOSAMENTE")
        success = True
        
    except Exception as e:
        print(f"\n‚ùå ERROR EN OPTIMIZACI√ìN: {e}")
        success = False
    
    sys.exit(0 if success else 1)
